<div align="center"><img src='https://github.com/xiaomile/ChineseMedicalAssistant/blob/main/images/lishizhen.png' width='500px'></div>

# ä¸­åŒ»è¯çŸ¥è¯†é—®ç­”åŠ©æ‰‹

***OpenXLab ä½“éªŒåœ°å€ï¼šhttps://openxlab.org.cn/apps/detail/xiaomile/medKnowledgeAssitant***

***ä¸­åŒ»è¯çŸ¥è¯†é—®ç­”åŠ©æ‰‹***

***ä¸‹è½½åœ°å€ï¼ˆåŸºåº§InternLM-chat-7bï¼‰ï¼šhttps://openxlab.org.cn/models/detail/xiaomile/ChineseMedicalAssistant_internlm***

***ä¸‹è½½åœ°å€ï¼ˆåŸºåº§InternLM2-chat-7bï¼‰ï¼šhttps://openxlab.org.cn/models/detail/xiaomile/ChineseMedicalAssistant_internlm2***

> *æ­¤ä»“åº“ä¸»è¦ç”¨äºå¾®è°ƒå¤§æ¨¡å‹ ï¼Œè¦å°†ä¸­åŒ»è¯çŸ¥è¯†é—®ç­”åŠ©æ‰‹éƒ¨ç½²åˆ°openxlabè¯·å‚è€ƒ[è¿™ä¸ªä»“åº“](https://github.com/xiaomile/ChineseMedicalAssistant2)*

## ä»‹ç»

&emsp;&emsp;ä¸­åŒ»è¯çŸ¥è¯†é—®ç­”åŠ©æ‰‹æ˜¯åˆ©ç”¨åŒ»å­¦ç™¾ç§‘ä¸­çš„æœ¬è‰çº²ç›®æ‰€è®°å½•çš„æ¯é¡¹ä¸­è¯çš„æ•°æ®ï¼ŒåŸºäº[InternLMå’ŒInternLM2](https://github.com/InternLM/InternLM.git)è¿›è¡ŒLoRAå¾®è°ƒå¾—åˆ°çš„åŒ»å­¦ç±»çš„é—®ç­”æ¨¡å‹ã€‚

> ä¸­åŒ»è¯çŸ¥è¯†æ˜¯ä¼ æ‰¿å‡ åƒå¹´çš„çŸ¥è¯†ç‘°å®ï¼Œå…¶ä¸­ã€Šæœ¬è‰çº²ç›®ã€‹æ˜¯ä¸€éƒ¨é›†å¤§æˆçš„ç»å…¸è‘—ä½œã€‚ä½œè€…æ˜¯æ˜æœçš„ææ—¶çï¼Œæ’°æˆäºä¸‡å†å…­å¹´ï¼ˆ1578 å¹´ï¼‰ï¼Œä¸‡å†äºŒåä¸‰å¹´ï¼ˆ1596å¹´ï¼‰åœ¨é‡‘é™µ(ä»Šå—äº¬)æ­£å¼åˆŠè¡Œã€‚å…¨ä¹¦äº”åäºŒå·ï¼Œæ”¶è½½è¯ç‰© 1892 ç§ï¼Œé™„è¯å›¾ 1100 ä½™å¹…ï¼Œé˜å‘è¯ç‰©çš„æ€§å‘³ã€ä¸»æ²»ã€ç”¨è¯æ³•åˆ™ã€äº§åœ°ã€å½¢æ€ã€é‡‡é›†ã€ç‚®åˆ¶ ã€æ–¹å‰‚é…ä¼ç­‰ï¼Œå¹¶è½½é™„æ–¹ 10000 ä½™ã€‚
ææ—¶çç”¨äº†å¤§çº¦27å¹´çš„æ—¶é—´æ‰ä¿®æ”¹ç¼–å†™å®Œæˆã€Šæœ¬è‰çº²ç›®ã€‹ï¼Œç»è¿‡äº†ä¸‰æ¬¡æ”¹å†™ï¼Œäºä¸‡å†å…­å¹´ï¼ˆ1578 å¹´ï¼‰æ‰æœ€ç»ˆå®Œæˆã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œææ—¶çå‚è€ƒäº†800å¤šç§ä¹¦ç±ï¼Œå¤šæ¬¡å»å„åœ°è¿›è¡Œå®åœ°è€ƒå¯Ÿï¼Œé‡‡é›†æ ·æœ¬ï¼Œè€—è´¹äº†ä»–éå¸¸å¤§çš„å¿ƒè¡€ã€‚

&emsp;&emsp;ä¸­åŒ»è¯çŸ¥è¯†é—®ç­”åŠ©æ‰‹ï¼Œå®ç°ä»¥ã€Šæœ¬è‰çº²ç›®ã€‹ä¸ºåˆ‡å…¥ç‚¹ï¼Œæ‰“é€ ä¸€å¥—åŸºäºä¸­åŒ»è¯çŸ¥è¯†ç™¾ç§‘çš„**ä¸ªæ€§åŒ– AI** å¾®è°ƒå¤§æ¨¡å‹å®Œæ•´æµç¨‹ï¼ŒåŒæ—¶ä¹Ÿåœ¨æ¢ç´¢AIæ—¶ä»£ä¸‹ä¸­åŒ»è¯çŸ¥è¯†ä¼ æ‰¿çš„è½½ä½“å½¢å¼ã€‚

> å…·ä½“å¦‚ä½•å®ç°å…¨æµç¨‹çš„ chat-AI å¾®è°ƒï¼Œå¯å‚è€ƒæœ¬ä»“åº“-[ChineseMedicalAssistant](https://github.com/xiaomile/ChineseMedicalAssistant.git)ã€‚
> 
> å¦‚ä½•å­¦ä¹ å¤§æ¨¡å‹éƒ¨ç½²å’Œå¾®è°ƒè¯·å‚è€ƒï¼š[å¼€æºå¤§æ¨¡å‹é£Ÿç”¨æŒ‡å—](https://github.com/datawhalechina/self-llm.git) ä»¥åŠ [ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥è¯¾ç¨‹](https://github.com/InternLM/tutorial.git)

&emsp;&emsp;***æ¬¢è¿å¤§å®¶æ¥ç»™[InternLM](https://github.com/InternLM/InternLM.git)ï¼Œç‚¹ç‚¹starå“¦~***

## *Fun è½¶äº‹*

<details>
<summary> å·å·è”ç½‘ or æ™ºèƒ½æ¶Œç°</summary>
    <div align="center">
        <img src='https://github.com/xiaomile/ChineseMedicalAssistant/blob/main/images/baizhusan.png' width='100%'>
        <img src='https://github.com/xiaomile/ChineseMedicalAssistant/blob/main/images/baizhusan2.png' width='100%'>
        <img src='https://github.com/xiaomile/ChineseMedicalAssistant/blob/main/images/baizhusan3.png' width='100%'>
    </div>
</details>

> åœ¨æŸä¸€æ¬¡å¾®è°ƒåçš„æµ‹è¯•ä¸­ï¼Œå°åŠ©æ‰‹çªç„¶è¾“å‡ºäº†ä¸€ä¸ªåä¸ºâ€œç™½æœ¯æ•£â€çš„è¯æ–¹ã€‚
>
> èµ·åˆè¿™ä¸ªå¹¶æ²¡æœ‰è®©æˆ‘æ„Ÿåˆ°å¥‡æ€ªï¼Œç›´åˆ°æˆ‘å¥½å¥‡åœ¨æ•°æ®é›†é‡Œæœäº†ä¸€ä¸‹â€œç™½æœ¯æ•£â€æ‰å‘ç°å‹æ ¹æ²¡æœ‰è¿™ä¸‰ä¸ªå­—
> 
> åæ¥åœ¨ç½‘ä¸Šæœäº†ä¸€ä¸‹ç™½æœ¯æ•£çš„ç›¸å…³ä¿¡æ¯ï¼ŒåŠŸæ•ˆå±…ç„¶å¯¹çš„ä¸Šã€‚
>
> è¿™è®©æˆ‘ä¸€åº¦æ€€ç–‘InternLMæ˜¯ä¸æ˜¯æœ‰è”ç½‘çš„åŠŸèƒ½ã€‚ã€‚ã€‚è¿˜æ˜¯è¯´è¿™å°±æ˜¯æ™ºèƒ½æ¶Œç°ï¼

<details>
    <summary> å½©è›‹ </summary>
    <div align="center">
        <img src='https://github.com/xiaomile/ChineseMedicalAssistant/blob/main/images/qinxin.png' width='100%'>
        <img src='https://github.com/xiaomile/ChineseMedicalAssistant/blob/main/images/qinxin2.png' width='100%'>
    </div>
</details>

> ä¸Šé¢æƒ…å†µçš„å¯ä»¥è¢«è§£é‡Šä¸ºççŒ«ç¢°ç€æ­»è€é¼ ï¼Œé‚£è¿™ä¸ªé˜ä¸‹åˆå¦‚ä½•åº”å¯¹ï¼Ÿ


## OpenXlab æ¨¡å‹

&emsp;&emsp;ä¸­åŒ»è¯çŸ¥è¯†é—®ç­”åŠ©æ‰‹ä½¿ç”¨çš„æ˜¯ InternLM2å’ŒInternLM çš„ 7B æ¨¡å‹ï¼Œæ¨¡å‹å‚æ•°é‡ä¸º 7Bï¼Œæ¨¡å‹å·²ä¸Šä¼ ï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½æ¨ç†ã€‚

| åŸºåº§æ¨¡å‹| å¾®è°ƒæ•°æ®é‡ | è®­ç»ƒæ¬¡æ•° | ä¸‹è½½åœ°å€ |
|:------:|:------:|:-------:|:---------|
|InternLM-chat-7b|46933 conversations|5 epochs|[xiaomile/ChineseMedicalAssistant_internlm](https://openxlab.org.cn/models/detail/xiaomile/ChineseMedicalAssistant_internlm)|
|InternLM2-chat-7b|46933 conversations|5 epochs|[xiaomile/ChineseMedicalAssistant_internlm2](https://openxlab.org.cn/models/detail/xiaomile/ChineseMedicalAssistant_internlm2)|
|InternLM-chat-7b|469330 conversations|4 epochs|[xiaomile/ChineseMedicalAssistant_internlm_40w_e4](https://openxlab.org.cn/models/detail/xiaomile/ChineseMedicalAssistant_internlm_40w_e4)|

***æ›´å¤§è®­ç»ƒé‡çš„æ¨¡å‹ coming soon...***

## æ•°æ®é›†

&emsp;&emsp;ä¸­åŒ»è¯çŸ¥è¯†é—®ç­”åŠ©æ‰‹ æ•°æ®é›†é‡‡ç”¨ä¸­çš„æœ¬è‰çº²ç›®æ‰€è®°å½•çš„æ¯é¡¹ä¸­è¯çš„æ•°æ®ï¼Œå…±è®¡ 7000 ä½™æ¡ï¼Œæ•°æ®é›†æ ·ä¾‹ï¼š

```text
input:éŸ­å“ªä¸ªéƒ¨ç±»
output:éŸ­æ‰€å±çš„éƒ¨æ˜¯èœéƒ¨
input:éŸ­åˆ«åæ˜¯ä»€ä¹ˆ
output:éŸ­çš„åç§°è§£é‡Šæ˜¯è‰é’Ÿä¹³ã€èµ·é˜³è‰ã€‚
input:éŸ­åƒèµ·æ¥è‹¦å˜›
output:éŸ­çš„æ°”å‘³æ˜¯éŸ­ï¼šè¾›ã€å¾®é…¸ã€æ¸©ã€æ¶©ã€æ— æ¯’ã€‚éŸ­å­ï¼šè¾›ã€ç”˜ã€æ¸©ã€æ— æ¯’ã€‚
input:éŸ­å¯ä»¥æ²»ä»€ä¹ˆç—‡çŠ¶
output:éŸ­çš„åŠŸæ•ˆæ˜¯ä¸»æ²»ï¼šèµ¤ç™½å¸¦ä¸‹;å–˜æ¯æ¬²ç»;ç–®ç™£;åˆ€ä¼¤å‡ºè¡€;ç›—æ±—;è€³å‡ºæ±;ç—¢ç–¾;æ¼†ç–®ä½œç—’;ä¼¤å¯’åŠ³å¤ï¼ˆæŒ‰ï¼šæŒ‡ä¼¤å¯’ç—…åï¼Œèº«ä½“æœªå¤åŸè€Œæ€§äº¤ï¼Œå¼•èµ·æ—§ç—…å¤å‘ï¼‰;é£Ÿç‰©ä¸­æ¯’;æ¶ˆæ¸´;èƒ¸ç—¹æ€¥ç—›ï¼ˆç—›å¦‚é”¥åˆºï¼Œä¸èƒ½ä¿¯ä»°ï¼Œè‡ªæ±—ï¼‰;é˜´é˜³æ˜“ç—…ï¼ˆç”·å­å› æˆ¿äº‹ä¸æ…ï¼Œå¼•èµ·é˜´éƒ¨è‚¿å¤§ï¼Œå°è…¹ç»ç—›ï¼Œå¤´é‡çœ¼èŠ±ï¼‰
```

<details><summary>æ•°æ®æ”¶é›†å’Œæ•´ç†è¿‡ç¨‹</summary>

> ä½¿ç”¨[è„šæœ¬](getdatafromweb.py)å°†æœ¬è‰çº²ç›®ä¸­å…³äºè¯æçš„é‡Šåã€æ°”å‘³å’Œä¸»æ²»æŒ‰æ‰€å±éƒ¨åˆ†åˆ«æŠ“å–ä¸‹æ¥åï¼Œå†æ•´åˆæˆä¸€ä¸ªæ–‡ä»¶ï¼Œä½œä¸ºæ•°æ®ä½¿ç”¨ã€‚æ¸©é¦¨æé†’ï¼šåƒä¸‡åˆ«æŠ“çš„å¤ªå¿«ï¼Œå¦åˆ™ä¼šè¢«æ‹‰è¿›å°é»‘å±‹ï¼Œåˆ«é—®æˆ‘ä¸ºä»€ä¹ˆçŸ¥é“ã€‚
>
> ä»ç½‘ä¸ŠæŠ“ä¸‹æ¥çš„æ•°æ®,åŠŸæ•ˆå’Œè¯æ–¹æ˜¯å†™åœ¨ä¸€èµ·çš„ï¼Œå› æ­¤è¿˜éœ€è¦ç»è¿‡å°†è¯æ–¹æç‚¼å‡ºæ¥ï¼Œåªä¿ç•™ä¸»æ²»çš„ç—‡çŠ¶åœ¨åŠŸæ•ˆæè¿°é‡Œï¼ˆç”±äºåŠŸæ•ˆæè¿°å¤§éƒ¨åˆ†æ˜¯æ ¼å¼å›ºå®šçš„ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨reå°†å…¶åˆ†ç¦»å‡ºæ¥ï¼Œåˆ†ç¦»å¯å‚è€ƒæ­¤[è„šæœ¬](SplitEfficacyAndSymptomatology.py)ï¼‰
>
> è„šæœ¬åˆ†ç¦»åè¿˜éœ€ç»è¿‡å‡ å¤©çš„äººå·¥ä¿®æ­£ï¼Œæ‰èƒ½å¾—åˆ°[æœ€ç»ˆçš„æ•ˆæœ](symptom.xlsx)
>
> ä½¿ç”¨[è„šæœ¬](xlsx2Andsympton2New.py)ç”Ÿæˆæ–°çš„xlsxï¼Œå‡†å¤‡åˆ›å»ºæ•°æ®é›†ã€‚
>
> ä½¿ç”¨[è„šæœ¬](xlsx2jsonl3.py)ç”Ÿæˆå¾®è°ƒç”¨çš„jsonlæ ¼å¼æ•°æ®é›†ï¼Œè‹¥éœ€è¦é‡å¤éšæœºæ•°æ®ï¼Œå¯å°†è„šæœ¬ä¸­çš„repeat_timesæ”¹æˆä½ æƒ³è¦é‡å¤çš„æ¬¡æ•°ã€‚
>
> æœ€åä½¿ç”¨[è„šæœ¬](split2train_and_test.py),åˆ†å¼€è®­ç»ƒé›†å’Œæµ‹è¯•é›†

</details>

## å¾®è°ƒ

&emsp;&emsp;ä½¿ç”¨ XTuner è®­ç»ƒï¼Œ XTuner æœ‰å„ä¸ªæ¨¡å‹çš„ä¸€é”®è®­ç»ƒè„šæœ¬ï¼Œå¾ˆæ–¹ä¾¿ã€‚ä¸”å¯¹ InternLM2 çš„æ”¯æŒåº¦æœ€é«˜ã€‚

### XTuner

&emsp;&emsp;ä½¿ç”¨ XTuner è¿›è¡Œå¾®è°ƒï¼Œå…·ä½“è„šæœ¬å¯å‚è€ƒ`configs`æ–‡ä»¶å¤¹ä¸‹çš„è„šæœ¬ï¼Œè„šæœ¬å†…æœ‰è¾ƒä¸ºè¯¦ç»†çš„æ³¨é‡Šã€‚

|åŸºåº§æ¨¡å‹|é…ç½®æ–‡ä»¶|
|:---:|:---:|
|internlm-chat-7b|[internlm_chat_7b_qlora_e3_chineseMed.py](configs/internlm_chat_7b_qlora_e3_chineseMed.py)|
|internlm2-chat-7b|[internlm2_chat_7b_qlora_e3_chineseMed.py](configs/internlm2_chat_7b_qlora_e3_chineseMed.py)|

<details><summary>å¾®è°ƒæ–¹æ³•å¦‚ä¸‹ï¼š</summary>

1. æ ¹æ®åŸºåº§æ¨¡å‹å¤åˆ¶ä¸Šé¢çš„é…ç½®æ–‡ä»¶ï¼Œå°†æ¨¡å‹åœ°å€`pretrained_model_name_or_path`å’Œæ•°æ®é›†åœ°å€`data_path`ä¿®æ”¹æˆè‡ªå·±çš„ï¼Œpropmtæ¨¡æ¿`prompt_template`éœ€è¦æ ¹æ®åŸºåº§æ¨¡å‹æ˜¯InternLMè¿˜æ˜¯InternLM2é€‰æ‹©`PROMPT_TEMPLATE.internlm_chat`è¿˜æ˜¯`PROMPT_TEMPLATE.internlm2_chat`ï¼Œå…¶ä»–å‚æ•°æ ¹æ®è‡ªå·±çš„éœ€æ±‚ä¿®æ”¹ï¼Œç„¶åå°±å¯ä»¥å¼€å§‹å¾®è°ƒï¼ˆå¾®è°ƒæ—¶é—´é•¿çš„æ¨èä½¿ç”¨tmuxï¼Œå…å¾—ä¸‡ä¸€å’Œæœºå™¨æ–­å¼€è¿æ¥å¯¼è‡´å¾®è°ƒä¸­æ–­ï¼‰

   ```bash
   xtuner train ${YOUR_CONFIG} --deepspeed deepspeed_zero2
   ```

   `--deepspeed` è¡¨ç¤ºä½¿ç”¨ [DeepSpeed](https://github.com/microsoft/DeepSpeed) ğŸš€ æ¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚XTuner å†…ç½®äº†å¤šç§ç­–ç•¥ï¼ŒåŒ…æ‹¬ ZeRO-1ã€ZeRO-2ã€ZeRO-3 ç­‰ã€‚å¦‚æœç”¨æˆ·æœŸæœ›å…³é—­æ­¤åŠŸèƒ½ï¼Œè¯·ç›´æ¥ç§»é™¤æ­¤å‚æ•°ã€‚

2. å°†ä¿å­˜çš„ `.pth` æ¨¡å‹ï¼ˆå¦‚æœä½¿ç”¨çš„DeepSpeedï¼Œåˆ™å°†ä¼šæ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼‰è½¬æ¢ä¸º HuggingFace Adapter æ¨¡å‹ï¼Œå³ï¼šç”Ÿæˆ Adapter æ–‡ä»¶å¤¹ï¼š

   ```bash
   export MKL_SERVICE_FORCE_INTEL=1
   xtuner convert pth_to_hf ${YOUR_CONFIG} ${PTH} ${LoRA_PATH}
   ```

3. å°† HuggingFace Adapter æ¨¡å‹åˆå¹¶å…¥ HuggingFace æ¨¡å‹ï¼š

    ```bash
    xtuner convert merge ${Base_PATH} ${LoRA_PATH} ${MERGED_PATH}
    ```

4. è‹¥çœŸçš„å‡ºç°æ„å¤–å¯¼è‡´å¾®è°ƒä¸­æ®µï¼Œå¯ä»¥ä»æœ€è¿‘çš„ checkpoint ç»§ç»­å¾®è°ƒ

   ```bash
   xtuner train ${YOUR_CONFIG} --deepspeed deepspeed_zero2 --resume ${LATEST_CHECKPOINT}
   ```

</details>

### Chat

å¾®è°ƒç»“æŸåå¯ä»¥ä½¿ç”¨xtuneræŸ¥çœ‹å¯¹è¯æ•ˆæœ

```shell
xtuner chat ${MERGED_PATH} [optional arguments]
```

<details><summary>å‚æ•°ï¼š</summary>
    
- `--prompt-template`: æŒ‡å®šå¯¹è¯æ¨¡æ¿ï¼Œä¸€ä»£æ¨¡å‹ä½¿ç”¨ internlm_chatï¼ŒäºŒä»£ä½¿ç”¨  internlm2_chatã€‚
- `--system`:  æŒ‡å®šSYSTEMæ–‡æœ¬
- `--system-template`:  æŒ‡å®šSYSTEMæ¨¡æ¿
- `--bits`:  LLMä½æ•°ï¼Œ{4,8,None}ã€‚é»˜è®¤ä¸º fp16ã€‚
- `--bot-name`:  botåç§°
- `--with-plugins`:  æŒ‡å®šè¦ä½¿ç”¨çš„æ’ä»¶
- `--no-streamer`:  æ˜¯å¦å¯ç”¨æµå¼ä¼ è¾“
- `--lagent`:  æ˜¯å¦ä½¿ç”¨lagent
- `--command-stop-word`:  å‘½ä»¤åœæ­¢è¯
- `--answer-stop-word`:  å›ç­”åœæ­¢è¯
- `--offload-folder`:  å­˜æ”¾æ¨¡å‹æƒé‡çš„æ–‡ä»¶å¤¹ï¼ˆæˆ–è€…å·²ç»å¸è½½æ¨¡å‹æƒé‡çš„æ–‡ä»¶å¤¹ï¼‰
- `--max-new-tokens`:  ç”Ÿæˆæ–‡æœ¬ä¸­å…è®¸çš„æœ€å¤§ token æ•°é‡
- `--temperature`:  æ¸©åº¦å€¼ï¼Œå¯¹äºäºŒä»£æ¨¡å‹ï¼Œå»ºè®®ä¸º0.8ã€‚
- `--top-k`:  ä¿ç•™ç”¨äºé¡¶kç­›é€‰çš„æœ€é«˜æ¦‚ç‡è¯æ±‡æ ‡è®°æ•°
- `--top-p`:  å¦‚æœè®¾ç½®ä¸ºå°äº1çš„æµ®ç‚¹æ•°ï¼Œä»…ä¿ç•™æ¦‚ç‡ç›¸åŠ é«˜äº top_p çš„æœ€å°ä¸€ç»„æœ€æœ‰å¯èƒ½çš„æ ‡è®°ï¼Œå¯¹äºäºŒä»£æ¨¡å‹ï¼Œå»ºè®®ä¸º0.8ã€‚
- `--repetition-penalty`: é˜²æ­¢æ–‡æœ¬é‡å¤è¾“å‡ºï¼Œå¯¹äºäºŒä»£æ¨¡å‹ï¼Œä¸ªäººå»ºè®®1.01ï¼Œå¯¹äºä¸€ä»£æ¨¡å‹å¯ä¸å¡«ã€‚
- `--seed`:  ç”¨äºå¯é‡ç°æ–‡æœ¬ç”Ÿæˆçš„éšæœºç§å­
- `-h`:  æŸ¥çœ‹å‚æ•°ã€‚
  
</details>

## OpenXLab éƒ¨ç½² ä¸­åŒ»è¯çŸ¥è¯†é—®ç­”åŠ©æ‰‹

&emsp;&emsp;ä»…éœ€è¦ Fork [æ­¤ä»“åº“](https://github.com/xiaomile/medKnowledgeAssitant)ï¼Œç„¶ååœ¨ OpenXLab ä¸Šåˆ›å»ºä¸€ä¸ªæ–°çš„é¡¹ç›®ï¼Œå°† Fork çš„ä»“åº“ä¸æ–°å»ºçš„é¡¹ç›®å…³è”ï¼Œå³å¯åœ¨ OpenXLab ä¸Šéƒ¨ç½² ä¸­åŒ»è¯çŸ¥è¯†é—®ç­”åŠ©æ‰‹ã€‚

&emsp;&emsp;***OPenXLab ä¸­åŒ»è¯çŸ¥è¯†é—®ç­”åŠ©æ‰‹  https://openxlab.org.cn/apps/detail/xiaomile/medKnowledgeAssitant***

![Alt text](images/openxlab.png)

## LmDeployéƒ¨ç½²

- é¦–å…ˆå®‰è£…LmDeploy

```shell
pip install -U 'lmdeploy[all]==v0.1.0'
```

- ç„¶åè½¬æ¢æ¨¡å‹ä¸º`turbomind`æ ¼å¼ã€‚ä½¿ç”¨ TurboMind æ¨ç†æ¨¡å‹éœ€è¦å…ˆå°†æ¨¡å‹è½¬åŒ–ä¸º TurboMind çš„æ ¼å¼ï¼Œï¼Œç›®å‰æ”¯æŒåœ¨çº¿è½¬æ¢å’Œç¦»çº¿è½¬æ¢ä¸¤ç§å½¢å¼ã€‚TurboMind æ˜¯ä¸€æ¬¾å…³äº LLM æ¨ç†çš„é«˜æ•ˆæ¨ç†å¼•æ“ï¼ŒåŸºäºè‹±ä¼Ÿè¾¾çš„ FasterTransformer ç ”å‘è€Œæˆã€‚å®ƒçš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼šLLaMa ç»“æ„æ¨¡å‹çš„æ”¯æŒï¼Œpersistent batch æ¨ç†æ¨¡å¼å’Œå¯æ‰©å±•çš„ KV ç¼“å­˜ç®¡ç†å™¨ã€‚
æœ¬é¡¹ç›®é‡‡ç”¨ç¦»çº¿è½¬æ¢ï¼Œéœ€è¦åœ¨å¯åŠ¨æœåŠ¡ä¹‹å‰ï¼Œå°†æ¨¡å‹è½¬ä¸º lmdeploy TurboMind çš„æ ¼å¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

> --dst-path: å¯ä»¥æŒ‡å®šè½¬æ¢åçš„æ¨¡å‹å­˜å‚¨ä½ç½®ã€‚

```shell
lmdeploy convert internlm2-chat-7b  è¦è½¬åŒ–çš„æ¨¡å‹åœ°å€ --dst-path è½¬æ¢åçš„æ¨¡å‹åœ°å€
```
æ‰§è¡Œå®Œæˆåå°†ä¼šåœ¨å½“å‰ç›®å½•ç”Ÿæˆä¸€ä¸ª workspace çš„æ–‡ä»¶å¤¹ã€‚

- LmDeploy Chatå¯¹è¯ã€‚æ¨¡å‹è½¬æ¢å®Œæˆåï¼Œæˆ‘ä»¬å°±å…·å¤‡äº†ä½¿ç”¨æ¨¡å‹æ¨ç†çš„æ¡ä»¶ï¼Œæ¥ä¸‹æ¥å°±å¯ä»¥è¿›è¡ŒçœŸæ­£çš„æ¨¡å‹æ¨ç†ç¯èŠ‚ã€‚
1ã€æœ¬åœ°å¯¹è¯ï¼ˆBash Local Chatï¼‰æ¨¡å¼ï¼Œå®ƒæ˜¯è·³è¿‡API Serverç›´æ¥è°ƒç”¨TurboMindã€‚ç®€å•æ¥è¯´ï¼Œå°±æ˜¯å‘½ä»¤è¡Œä»£ç ç›´æ¥æ‰§è¡Œ TurboMindã€‚
```shell
lmdeploy chat turbomind è½¬æ¢åçš„turbomindæ¨¡å‹åœ°å€/workspace
```

- ç½‘é¡µDemoæ¼”ç¤ºã€‚æœ¬é¡¹ç›®é‡‡ç”¨å°†TurboMindæ¨ç†ä½œä¸ºåç«¯ï¼Œå°†Gradioä½œä¸ºå‰ç«¯Demoæ¼”ç¤ºã€‚
```shell
# Gradio+Turbomind(local)
lmdeploy serve gradio è½¬æ¢åçš„turbomindæ¨¡å‹åœ°å€/workspace
```
å°±å¯ä»¥ç›´æ¥å¯åŠ¨ Gradioï¼Œæ­¤æ—¶æ²¡æœ‰API Serverï¼ŒTurboMindç›´æ¥ä¸Gradioé€šä¿¡ã€‚

## Lmdeploy&opencompass é‡åŒ–ä»¥åŠé‡åŒ–è¯„æµ‹  
> è¿›è¡Œé‡åŒ–å†³ç­–æµç¨‹
> Step1:å°è¯•æ­£å¸¸ç‰ˆæœ¬ï¼Œè¯„ä¼°æ•ˆæœã€‚æ•ˆæœä¸€èˆ¬ï¼Œå¯åŠ¨é‡åŒ–ã€‚
> Step2:å¼€å±•KV Cacheé‡åŒ–ï¼Œä»¥å‡å°‘ä¸­é—´è¿‡ç¨‹è®¡ç®—ç»“æœå¯¹æ˜¾å­˜çš„å ç”¨ã€‚è¯„ä¼°é‡åŒ–æ•ˆæœã€‚
### `KV Cache`é‡åŒ– 
- è®¡ç®—ä¸è·å¾—é‡åŒ–å‚æ•°
  >è®¡ç®— minmaxã€‚ä¸»è¦æ€è·¯æ˜¯é€šè¿‡è®¡ç®—ç»™å®šè¾“å…¥æ ·æœ¬åœ¨æ¯ä¸€å±‚ä¸åŒä½ç½®å¤„è®¡ç®—ç»“æœçš„ç»Ÿè®¡æƒ…å†µã€‚
  >åœ¨è®¡ç®—minmaxçš„å‘½ä»¤è¡Œä¸­ï¼Œä¼šé€‰æ‹©128æ¡è¾“å…¥æ ·æœ¬ï¼Œæ¯æ¡æ ·æœ¬é•¿åº¦ä¸º 2048ï¼Œæ•°æ®é›†é€‰æ‹©ptbï¼Œè¾“å…¥æ¨¡å‹åå°±ä¼šå¾—åˆ°ä¸Šé¢çš„å„ç§ç»Ÿè®¡å€¼ã€‚
```shell
# è®¡ç®— minmax
lmdeploy lite calibrate \
  --model  æ¨¡å‹è·¯å¾„ \
  --calib_dataset "ptb" \
  --calib_samples 128 \
  --calib_seqlen 2048 \
  --work_dir ./quant_output #å‚æ•°ä¿å­˜è·¯å¾„
```
  >é€šè¿‡minmaxè·å–é‡åŒ–å‚æ•°ã€‚ä¸»è¦åˆ©ç”¨ä¸‹é¢å…¬å¼æ¥è·å–æ¯ä¸€å±‚çš„KVä¸­å¿ƒå€¼ï¼ˆzpï¼‰å’Œç¼©æ”¾å€¼ï¼ˆscaleï¼‰ã€‚
```shell
zp = (min+max) / 2
scale = (max-min) / 255
quant: q = round( (f-zp) / scale)
dequant: f = q * scale + zp
```
  >æœ‰äº†è¿™ä¸¤ä¸ªå€¼å°±å¯ä»¥è¿›è¡Œé‡åŒ–å’Œåé‡åŒ–æ“ä½œã€‚å…·ä½“æ¥è¯´å°±æ˜¯å¯¹å†å²å­˜å‚¨ä¸­çš„Kå’ŒVåšé‡åŒ–ï¼Œä½¿ç”¨æ—¶å†åé‡åŒ–ã€‚ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼š
```shell
# é€šè¿‡ minmax è·å–é‡åŒ–å‚æ•°
lmdeploy lite kv_qparams \
  --work_dir ./quant_output #å‚æ•°ä¿å­˜è·¯å¾„ \
  --turbomind_dir workspace/triton_models/weights/ #è½¬æ¢åæ¨¡å‹è·¯å¾„ \
  --kv_sym False \
  --num_tp 1
```
- ä¿®æ”¹é…ç½®ã€‚ä¿®æ”¹weights/config.iniæ–‡ä»¶ï¼ŒæŠŠquant_policyæ”¹ä¸º4ï¼Œä»è€Œæ‰“å¼€KV int8å¼€å…³ã€‚
```shell
tensor_para_size = 1
session_len = 2056
max_batch_size = 64
max_context_token_num = 1
step_length = 1
cache_max_entry_count = 0.5
cache_block_seq_len = 128
cache_chunk_size = 1
use_context_fmha = 1
quant_policy = 4
max_position_embeddings = 2048
rope_scaling_factor = 0.0
use_logn_attn = 0
```
  >è‡³æ­¤å°±å®Œæˆäº†KV Cacheé‡åŒ–ã€‚
- è¯„ä¼°é‡åŒ–æ•ˆæœã€‚ç¼–å†™è¯„æµ‹æ–‡ä»¶`configs/eval_turbomind.py`
```python
from mmengine.config import read_base
from opencompass.models.turbomind import TurboMindModel

with read_base():
 # choose a list of datasets   
  from .datasets.ceval.ceval_gen import ceval_datasets 
 # and output the results in a choosen format
  from .summarizers.medium import summarizer

datasets = [*ceval_datasets]

internlm2_chat_7b = dict(
     type=TurboMindModel,
     abbr='internlm2-chat-7b-turbomind',
     path='è½¬æ¢åçš„æ¨¡å‹åœ°å€',
     engine_config=dict(session_len=512,
         max_batch_size=2,
         rope_scaling_factor=1.0),
     gen_config=dict(top_k=1,
         top_p=0.8,
         temperature=1.0,
         max_new_tokens=100),
     max_out_len=100,
     max_seq_len=512,
     batch_size=2,
     concurrency=1,
     #  meta_template=internlm_meta_template,
     run_cfg=dict(num_gpus=1, num_procs=1),
)
models = [internlm2_chat_7b]
```
- å¯åŠ¨è¯„æµ‹ï¼
```shell
python run.py configs/eval_turbomind.py -w æŒ‡å®šç»“æœä¿å­˜è·¯å¾„
```
> Step3:å¼€å±•W4A16é‡åŒ–ï¼Œä»¥å‡å°‘æ¨¡å‹å‚æ•°è®¡ç®—ç»“æœå¯¹æ˜¾å­˜çš„å ç”¨ã€‚è¯„ä¼°é‡åŒ–æ•ˆæœã€‚W4A16ä¸­çš„Aæ˜¯æŒ‡Activationï¼Œä¿æŒFP16ï¼Œåªå¯¹éƒ¨åˆ†æƒé‡å‚æ•°è¿›è¡Œ4bité‡åŒ–
### `W4A16`é‡åŒ– 
- è®¡ç®—ä¸è·å¾—é‡åŒ–å‚æ•°
  >è®¡ç®— minmaxã€‚ä¸»è¦æ€è·¯æ˜¯é€šè¿‡è®¡ç®—ç»™å®šè¾“å…¥æ ·æœ¬åœ¨æ¯ä¸€å±‚ä¸åŒä½ç½®å¤„è®¡ç®—ç»“æœçš„ç»Ÿè®¡æƒ…å†µã€‚
  >åœ¨è®¡ç®—minmaxçš„å‘½ä»¤è¡Œä¸­ï¼Œä¼šé€‰æ‹©128æ¡è¾“å…¥æ ·æœ¬ï¼Œæ¯æ¡æ ·æœ¬é•¿åº¦ä¸º 2048ï¼Œæ•°æ®é›†é€‰æ‹©ptbï¼Œè¾“å…¥æ¨¡å‹åå°±ä¼šå¾—åˆ°ä¸Šé¢çš„å„ç§ç»Ÿè®¡å€¼ã€‚
```shell
# è®¡ç®— minmax
lmdeploy lite calibrate \
  --model  æ¨¡å‹è·¯å¾„ \
  --calib_dataset "ptb" \
  --calib_samples 128 \
  --calib_seqlen 2048 \
  --work_dir ./quant_output #å‚æ•°ä¿å­˜è·¯å¾„
```
- é‡åŒ–æƒé‡æ¨¡å‹
  >åˆ©ç”¨ä¸Šé¢å¾—åˆ°çš„ç»Ÿè®¡å€¼å¯¹å‚æ•°è¿›è¡Œé‡åŒ–ã€‚
  >å…·ä½“åŒ…æ‹¬ä¸¤æ­¥ï¼Œåˆ†åˆ«æ˜¯ç¼©æ”¾å‚æ•°å’Œæ•´ä½“é‡åŒ–ã€‚
  >æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š
```shell
# é‡åŒ–æƒé‡æ¨¡å‹
lmdeploy lite auto_awq \
  --model  #æ¨¡å‹å­˜æ”¾è·¯å¾„ \
  --w_bits 4 \
  --w_group_size 128 \
  --work_dir ./quant_output #æ¨¡å‹å­˜æ”¾è·¯å¾„
```
  >å‘½ä»¤ä¸­ w_bitsè¡¨ç¤ºé‡åŒ–çš„ä½æ•°ï¼Œw_group_sizeè¡¨ç¤ºé‡åŒ–åˆ†ç»„ç»Ÿè®¡çš„å°ºå¯¸ï¼Œwork_diræ˜¯é‡åŒ–åæ¨¡å‹è¾“å‡ºçš„ä½ç½®ã€‚
  >å› ä¸ºæ²¡æœ‰ torch.int4ï¼Œæ‰€ä»¥å®é™…å­˜å‚¨æ—¶ï¼Œ8ä¸ª4bitæƒé‡ä¼šè¢«æ‰“åŒ…åˆ°ä¸€ä¸ªint32å€¼ä¸­ã€‚
- è½¬æ¢æˆ TurboMind æ ¼å¼
```shell
# è½¬æ¢æ¨¡å‹çš„layoutï¼Œå­˜æ”¾åœ¨é»˜è®¤è·¯å¾„ ./workspace ä¸‹
lmdeploy convert  internlm-chat-7b ./quant_output #KV Cacheé‡åŒ–åçš„æ¨¡å‹è·¯å¾„\
    --model-format awq \
    --group-size 128
    --dst_path ./workspace_quant #è½¬æ¢åæ¨¡å‹å­˜æ”¾è·¯å¾„
```
  >è¿™ä¸ªgroup-sizeå°±æ˜¯é‚£ä¸ªw_group_sizeã€‚å¯ä»¥æŒ‡å®šè¾“å‡ºç›®å½•ï¼š--dst_pathã€‚
  >è‡³æ­¤å°±å®Œæˆäº†KV Cacheé‡åŒ–ã€‚

- è¯„ä¼°é‡åŒ–æ•ˆæœã€‚è¯„æµ‹æ–‡ä»¶`configs/eval_turbomind.py`å¦‚ä¸Š
- å¯åŠ¨è¯„æµ‹ï¼
```shell
python run.py configs/eval_turbomind.py -w ç»“æœä¿å­˜è·¯å¾„
```
ç»“æœæ–‡ä»¶å¯åœ¨åŒç›®å½•æ–‡ä»¶[results](./results)ä¸­è·å–

## OpenCompass è¯„æµ‹

- å®‰è£… OpenCompass

```shell
git clone https://github.com/open-compass/opencompass
cd opencompass
pip install -e .
```

- ä¸‹è½½è§£å‹æ•°æ®é›†

```shell
cp /share/temp/datasets/OpenCompassData-core-20231110.zip /root/opencompass/
unzip OpenCompassData-core-20231110.zip
```

- è¯„æµ‹å¯åŠ¨ï¼

```shell
python run.py \
    --datasets ceval_gen \
    --hf-path /root/ChineseMedicalAssistant/merged2 \
    --tokenizer-path /root/ChineseMedicalAssistant/merged2 \
    --tokenizer-kwargs padding_side='left' truncation='left'     trust_remote_code=True \
    --model-kwargs device_map='auto' trust_remote_code=True \
    --max-seq-len 2048 \
    --max-out-len 16 \
    --batch-size 2  \
    --num-gpus 1 \
    --debug
```
  

## è‡´è°¢

<div align="center">

***æ„Ÿè°¢ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ç»„ç»‡çš„ ä¹¦ç”ŸÂ·æµ¦è¯­å®æˆ˜è¥ å­¦ä¹ æ´»åŠ¨~***

***æ„Ÿè°¢ OpenXLab å¯¹é¡¹ç›®éƒ¨ç½²çš„ç®—åŠ›æ”¯æŒ~***

***æ„Ÿè°¢ æµ¦è¯­å°åŠ©æ‰‹ å¯¹é¡¹ç›®çš„æ”¯æŒ~***
</div>

